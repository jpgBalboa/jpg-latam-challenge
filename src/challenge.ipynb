{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latam Challenge\n",
    "Para ejecutar el codigo es necesario instalar las librerias del requirements.txt, ejecutar en la terminal \"pip install -r requirements.txt\"\n",
    "Como el archivo esta compartido en Drive, lo descargaremos y lo dejaremos en una carpeta dentro del proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descarga del archivo desde Google Drive\n",
    "import gdown\n",
    "import os\n",
    "\n",
    "file_id = \"1ig2ngoXFTxP5Pa8muXo02mDTFexZzsis\"\n",
    "output_path = \"tweets_json/farmers-protest-tweets-2021-2-4.zip\"\n",
    "\n",
    "# Crear carpeta si no existe\n",
    "os.makedirs(\"tweets_json\", exist_ok=True)\n",
    "\n",
    "# Descargar el archivo ZIP\n",
    "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_path, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ya tenemos el archivo, debemos descomprimir el .zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(output_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"tweets_json\")\n",
    "\n",
    "# Verifica el contenido extraído\n",
    "print(\"Contenido de tweets_json:\", os.listdir(\"tweets_json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se declara la variable que posee el .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"tweets_json/farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 Fechas y Usuario\n",
    "## q1_time\n",
    "Para este caso se leyo la informacion del .json y se almaceno en un DataFrame, con esto se hacia mas facil poder procesar la informacion y aplicar las logicas que eran requeridas. Se realiza la agrupacion de date y username, para realizar un conteo.\n",
    "\n",
    "## q2_memory\n",
    "En este caso lo que se realizo fue recorrer el archivo .json linea por linea y realizar un conteo de los datos que se necesitaban, para eso tambien solo se utilizan los campos de date y username. Se obtienen las 10 fechas con mas tweets y por cada una el usuario mas activo.\n",
    "\n",
    "PD: Al realizar diferentes iteraciones no me entregaba los resultados o simplemente no me entregaba nada, es por eso que genere diferentes \"Print()\" con el fin de ir detectando en donde el codigo dejaba de obtener datos. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados por tiempo:\n",
      "Total tweets cargados: 117407\n",
      "Fechas convertidas, ejemplo: 2021-02-24\n",
      "Usuario ejemplo: ArjunSinghPanam\n",
      "Fechas únicas: 13\n",
      "Top 10 fechas: [datetime.date(2021, 2, 12), datetime.date(2021, 2, 13), datetime.date(2021, 2, 17), datetime.date(2021, 2, 16), datetime.date(2021, 2, 14), datetime.date(2021, 2, 18), datetime.date(2021, 2, 15), datetime.date(2021, 2, 20), datetime.date(2021, 2, 23), datetime.date(2021, 2, 19)]\n",
      "Tweets filtrados por fechas top: 99367\n",
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 19), 'Preetm91'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria')]\n",
      "*****************************************\n",
      "Resultados por memoria:\n",
      "10000 tweets procesados correctamente\n",
      "20000 tweets procesados correctamente\n",
      "30000 tweets procesados correctamente\n",
      "40000 tweets procesados correctamente\n",
      "50000 tweets procesados correctamente\n",
      "60000 tweets procesados correctamente\n",
      "70000 tweets procesados correctamente\n",
      "80000 tweets procesados correctamente\n",
      "90000 tweets procesados correctamente\n",
      "100000 tweets procesados correctamente\n",
      "110000 tweets procesados correctamente\n",
      "\n",
      "Resumen del procesamiento\n",
      "Líneas totales leídas: 117407\n",
      "Tweets válidos: 117407\n",
      "Errores: 0\n",
      "Fechas únicas encontradas: 13\n",
      "Top 10 fechas con más tweets: [datetime.date(2021, 2, 12), datetime.date(2021, 2, 13), datetime.date(2021, 2, 17), datetime.date(2021, 2, 16), datetime.date(2021, 2, 14), datetime.date(2021, 2, 18), datetime.date(2021, 2, 15), datetime.date(2021, 2, 20), datetime.date(2021, 2, 23), datetime.date(2021, 2, 19)]\n",
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "from q1_time import q1_time\n",
    "from q1_memory import q1_memory\n",
    "\n",
    "\n",
    "print(\"Resultados por tiempo:\")\n",
    "print(q1_time(file_path))\n",
    "print(\"*****************************************\")\n",
    "print(\"Resultados por memoria:\")\n",
    "print(q1_memory(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "10000 tweets procesados correctamente\n",
      "20000 tweets procesados correctamente\n",
      "30000 tweets procesados correctamente\n",
      "40000 tweets procesados correctamente\n",
      "50000 tweets procesados correctamente\n",
      "60000 tweets procesados correctamente\n",
      "70000 tweets procesados correctamente\n",
      "80000 tweets procesados correctamente\n",
      "90000 tweets procesados correctamente\n",
      "100000 tweets procesados correctamente\n",
      "110000 tweets procesados correctamente\n",
      "\n",
      "Resumen del procesamiento\n",
      "Líneas totales leídas: 117407\n",
      "Tweets válidos: 117407\n",
      "Errores: 0\n",
      "Fechas únicas encontradas: 13\n",
      "Top 10 fechas con más tweets: [datetime.date(2021, 2, 12), datetime.date(2021, 2, 13), datetime.date(2021, 2, 17), datetime.date(2021, 2, 16), datetime.date(2021, 2, 14), datetime.date(2021, 2, 18), datetime.date(2021, 2, 15), datetime.date(2021, 2, 20), datetime.date(2021, 2, 23), datetime.date(2021, 2, 19)]\n",
      "peak memory: 162.66 MiB, increment: 2.74 MiB\n",
      "⏱ Tiempo total: 5.94 segundos\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "%load_ext line_profiler\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "%memit q1_memory(file_path)\n",
    "print(f\"Tiempo total: {time.time() - start:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "10000 tweets procesados correctamente\n",
      "20000 tweets procesados correctamente\n",
      "30000 tweets procesados correctamente\n",
      "40000 tweets procesados correctamente\n",
      "50000 tweets procesados correctamente\n",
      "60000 tweets procesados correctamente\n",
      "70000 tweets procesados correctamente\n",
      "80000 tweets procesados correctamente\n",
      "90000 tweets procesados correctamente\n",
      "100000 tweets procesados correctamente\n",
      "110000 tweets procesados correctamente\n",
      "\n",
      "Resumen del procesamiento\n",
      "Líneas totales leídas: 117407\n",
      "Tweets válidos: 117407\n",
      "Errores: 0\n",
      "Fechas únicas encontradas: 13\n",
      "Top 10 fechas con más tweets: [datetime.date(2021, 2, 12), datetime.date(2021, 2, 13), datetime.date(2021, 2, 17), datetime.date(2021, 2, 16), datetime.date(2021, 2, 14), datetime.date(2021, 2, 18), datetime.date(2021, 2, 15), datetime.date(2021, 2, 20), datetime.date(2021, 2, 23), datetime.date(2021, 2, 19)]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: c:\\Users\\JP\\Documents\\repo_git\\desafioDE\\src\\q1_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     7    160.7 MiB    160.7 MiB           1   def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "     8    161.7 MiB     -0.6 MiB          27       date_user_count = defaultdict(lambda: defaultdict(int))\n",
      "     9    160.7 MiB      0.0 MiB           1       total_lines = 0\n",
      "    10    160.7 MiB      0.0 MiB           1       registros_ok = 0\n",
      "    11    160.7 MiB      0.0 MiB           1       errores = 0\n",
      "    12                                         \n",
      "    13    162.1 MiB      0.0 MiB           2       with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
      "    14    162.1 MiB  -5511.0 MiB      117408           for line in f:\n",
      "    15    162.1 MiB  -5512.7 MiB      117407               total_lines += 1\n",
      "    16    162.1 MiB  -5512.9 MiB      117407               try:\n",
      "    17    162.1 MiB  -5441.4 MiB      117407                   tweet = json.loads(line)\n",
      "    18                                         \n",
      "    19                                                         # Verificación explícita de campos requeridos\n",
      "    20    162.1 MiB  -5441.7 MiB      117407                   if \"date\" not in tweet or \"user\" not in tweet or \"username\" not in tweet[\"user\"]:\n",
      "    21                                                             print(f\"Línea {total_lines} incompleta o mal formada\")\n",
      "    22                                                             continue\n",
      "    23                                         \n",
      "    24    162.1 MiB  -5513.5 MiB      117407                   raw_date = tweet[\"date\"]\n",
      "    25    162.1 MiB  -5513.7 MiB      117407                   username = tweet[\"user\"][\"username\"]\n",
      "    26    162.1 MiB  -5514.0 MiB      117407                   date = parser.isoparse(raw_date).date()\n",
      "    27                                         \n",
      "    28    162.1 MiB  -5512.4 MiB      117407                   date_user_count[date][username] += 1\n",
      "    29    162.1 MiB  -5513.3 MiB      117407                   registros_ok += 1\n",
      "    30                                         \n",
      "    31    162.1 MiB  -5513.5 MiB      117407                   if registros_ok % 10000 == 0:\n",
      "    32    161.8 MiB     -0.4 MiB          11                       print(f\"{registros_ok} tweets procesados correctamente\")\n",
      "    33                                         \n",
      "    34                                                     except Exception as e:\n",
      "    35                                                         errores += 1\n",
      "    36                                                         print(f\"Error en línea {total_lines}: {e}\")\n",
      "    37                                                         print(\"Contenido:\", line.strip())\n",
      "    38                                                         if errores >= 5:\n",
      "    39                                                             print(\"Demasiados errores consecutivos, deteniendo ejecución.\")\n",
      "    40                                                             break\n",
      "    41                                         \n",
      "    42    162.1 MiB      0.0 MiB           1       print(\"\\nResumen del procesamiento\")\n",
      "    43    162.1 MiB      0.0 MiB           1       print(f\"Líneas totales leídas: {total_lines}\")\n",
      "    44    162.1 MiB      0.0 MiB           1       print(f\"Tweets válidos: {registros_ok}\")\n",
      "    45    162.1 MiB      0.0 MiB           1       print(f\"Errores: {errores}\")\n",
      "    46    162.1 MiB      0.0 MiB           1       print(f\"Fechas únicas encontradas: {len(date_user_count)}\")\n",
      "    47                                         \n",
      "    48    162.1 MiB      0.0 MiB          16       total_by_date = {d: sum(users.values()) for d, users in date_user_count.items()}\n",
      "    49    162.1 MiB      0.0 MiB           1       top10_dates = sorted(total_by_date, key=total_by_date.get, reverse=True)[:10]\n",
      "    50    162.1 MiB      0.0 MiB           1       print(\"Top 10 fechas con más tweets:\", top10_dates)\n",
      "    51                                         \n",
      "    52    162.1 MiB      0.0 MiB           1       result = []\n",
      "    53    162.1 MiB     -0.5 MiB          11       for d in top10_dates:\n",
      "    54    162.1 MiB     -0.4 MiB          10           user_counts = date_user_count[d]\n",
      "    55    162.1 MiB     -0.4 MiB          10           if user_counts:\n",
      "    56    162.1 MiB  -3953.5 MiB       88328               top_user = max(user_counts.items(), key=lambda x: x[1])[0]\n",
      "    57    162.1 MiB     -0.5 MiB          10               result.append((d, top_user))\n",
      "    58                                         \n",
      "    59    162.0 MiB     -0.1 MiB           1       return result"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "\n",
    "from q1_memory import q1_memory\n",
    "\n",
    "def wrapper():\n",
    "    return q1_memory(file_path)\n",
    "\n",
    "%mprun -f q1_memory wrapper()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
