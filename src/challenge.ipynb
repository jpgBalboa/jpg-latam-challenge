{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latam Challenge\n",
    "Para ejecutar el codigo es necesario instalar las librerias del requirements.txt, ejecutar en la terminal \"pip install -r requirements.txt\"\n",
    "Como el archivo esta compartido en Drive, lo descargaremos y lo dejaremos en una carpeta dentro del proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1ig2ngoXFTxP5Pa8muXo02mDTFexZzsis\n",
      "From (redirected): https://drive.google.com/uc?id=1ig2ngoXFTxP5Pa8muXo02mDTFexZzsis&confirm=t&uuid=732e3921-24fa-42c2-b0ef-ebef40ca7153\n",
      "To: c:\\Users\\JP\\Documents\\repo_git\\desafioDE\\src\\tweets_json\\farmers-protest-tweets-2021-2-4.zip\n",
      "100%|██████████| 60.4M/60.4M [00:01<00:00, 31.8MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tweets_json/farmers-protest-tweets-2021-2-4.zip'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descarga del archivo desde Google Drive\n",
    "import gdown\n",
    "import os\n",
    "\n",
    "file_id = \"1ig2ngoXFTxP5Pa8muXo02mDTFexZzsis\"\n",
    "output_path = \"tweets_json/farmers-protest-tweets-2021-2-4.zip\"\n",
    "\n",
    "# Crear carpeta si no existe\n",
    "os.makedirs(\"tweets_json\", exist_ok=True)\n",
    "\n",
    "# Descargar el archivo ZIP\n",
    "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_path, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ya tenemos el archivo, debemos descomprimir el .zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenido de tweets_json: ['farmers-protest-tweets-2021-2-4.json', 'farmers-protest-tweets-2021-2-4.zip']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(output_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"tweets_json\")\n",
    "\n",
    "# Verifica el contenido extraído\n",
    "print(\"Contenido de tweets_json:\", os.listdir(\"tweets_json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se declara la variable que posee el .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"tweets_json/farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 Fechas y Usuario\n",
    "## q1_time\n",
    "Para este caso se leyó la información del .json y se almaceno en un DataFrame, con esto se hacía más fácil poder procesar la información y aplicar las lógicas que eran requeridas. Se realiza la agrupación de date y username, para realizar un conteo.\n",
    "\n",
    "## q2_memory\n",
    "En este caso lo que se realizo fue recorrer el archivo .json línea por línea y realizar un conteo de los datos que se necesitaban, para eso también solo se utilizan los campos de date y username. Se obtienen las 10 fechas con más tweets y por cada una el usuario más activo.\n",
    "\n",
    "PD: Al realizar diferentes iteraciones no me entregaba los resultados o simplemente no me entregaba nada, es por esto que genere diferentes \"Print()\" con el fin de ir detectando en donde el código dejaba de obtener datos. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados por tiempo:\n",
      "Total tweets cargados: 117407\n",
      "Fechas convertidas, ejemplo: 2021-02-24\n",
      "Usuario ejemplo: ArjunSinghPanam\n",
      "Fechas únicas: 13\n",
      "Top 10 fechas: [datetime.date(2021, 2, 12), datetime.date(2021, 2, 13), datetime.date(2021, 2, 17), datetime.date(2021, 2, 16), datetime.date(2021, 2, 14), datetime.date(2021, 2, 18), datetime.date(2021, 2, 15), datetime.date(2021, 2, 20), datetime.date(2021, 2, 23), datetime.date(2021, 2, 19)]\n",
      "Tweets filtrados por fechas top: 99367\n",
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 19), 'Preetm91'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria')]\n",
      "*****************************************\n",
      "Resultados por memoria:\n",
      "10000 tweets procesados correctamente\n",
      "20000 tweets procesados correctamente\n",
      "30000 tweets procesados correctamente\n",
      "40000 tweets procesados correctamente\n",
      "50000 tweets procesados correctamente\n",
      "60000 tweets procesados correctamente\n",
      "70000 tweets procesados correctamente\n",
      "80000 tweets procesados correctamente\n",
      "90000 tweets procesados correctamente\n",
      "100000 tweets procesados correctamente\n",
      "110000 tweets procesados correctamente\n",
      "\n",
      "Resumen del procesamiento\n",
      "Líneas totales leídas: 117407\n",
      "Tweets válidos: 117407\n",
      "Errores: 0\n",
      "Fechas únicas encontradas: 13\n",
      "Top 10 fechas con más tweets: [datetime.date(2021, 2, 12), datetime.date(2021, 2, 13), datetime.date(2021, 2, 17), datetime.date(2021, 2, 16), datetime.date(2021, 2, 14), datetime.date(2021, 2, 18), datetime.date(2021, 2, 15), datetime.date(2021, 2, 20), datetime.date(2021, 2, 23), datetime.date(2021, 2, 19)]\n",
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "from q1_time import q1_time\n",
    "from q1_memory import q1_memory\n",
    "\n",
    "\n",
    "print(\"Resultados por tiempo:\")\n",
    "print(q1_time(file_path))\n",
    "print(\"*****************************************\")\n",
    "print(\"Resultados por memoria:\")\n",
    "print(q1_memory(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "10000 tweets procesados correctamente\n",
      "20000 tweets procesados correctamente\n",
      "30000 tweets procesados correctamente\n",
      "40000 tweets procesados correctamente\n",
      "50000 tweets procesados correctamente\n",
      "60000 tweets procesados correctamente\n",
      "70000 tweets procesados correctamente\n",
      "80000 tweets procesados correctamente\n",
      "90000 tweets procesados correctamente\n",
      "100000 tweets procesados correctamente\n",
      "110000 tweets procesados correctamente\n",
      "\n",
      "Resumen del procesamiento\n",
      "Líneas totales leídas: 117407\n",
      "Tweets válidos: 117407\n",
      "Errores: 0\n",
      "Fechas únicas encontradas: 13\n",
      "Top 10 fechas con más tweets: [datetime.date(2021, 2, 12), datetime.date(2021, 2, 13), datetime.date(2021, 2, 17), datetime.date(2021, 2, 16), datetime.date(2021, 2, 14), datetime.date(2021, 2, 18), datetime.date(2021, 2, 15), datetime.date(2021, 2, 20), datetime.date(2021, 2, 23), datetime.date(2021, 2, 19)]\n",
      "peak memory: 162.66 MiB, increment: 2.74 MiB\n",
      "⏱ Tiempo total: 5.94 segundos\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "%load_ext line_profiler\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "%memit q1_memory(file_path)\n",
    "print(f\"Tiempo total: {time.time() - start:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "10000 tweets procesados correctamente\n",
      "20000 tweets procesados correctamente\n",
      "30000 tweets procesados correctamente\n",
      "40000 tweets procesados correctamente\n",
      "50000 tweets procesados correctamente\n",
      "60000 tweets procesados correctamente\n",
      "70000 tweets procesados correctamente\n",
      "80000 tweets procesados correctamente\n",
      "90000 tweets procesados correctamente\n",
      "100000 tweets procesados correctamente\n",
      "110000 tweets procesados correctamente\n",
      "\n",
      "Resumen del procesamiento\n",
      "Líneas totales leídas: 117407\n",
      "Tweets válidos: 117407\n",
      "Errores: 0\n",
      "Fechas únicas encontradas: 13\n",
      "Top 10 fechas con más tweets: [datetime.date(2021, 2, 12), datetime.date(2021, 2, 13), datetime.date(2021, 2, 17), datetime.date(2021, 2, 16), datetime.date(2021, 2, 14), datetime.date(2021, 2, 18), datetime.date(2021, 2, 15), datetime.date(2021, 2, 20), datetime.date(2021, 2, 23), datetime.date(2021, 2, 19)]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: c:\\Users\\JP\\Documents\\repo_git\\desafioDE\\src\\q1_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     7    160.7 MiB    160.7 MiB           1   def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "     8    161.7 MiB     -0.6 MiB          27       date_user_count = defaultdict(lambda: defaultdict(int))\n",
      "     9    160.7 MiB      0.0 MiB           1       total_lines = 0\n",
      "    10    160.7 MiB      0.0 MiB           1       registros_ok = 0\n",
      "    11    160.7 MiB      0.0 MiB           1       errores = 0\n",
      "    12                                         \n",
      "    13    162.1 MiB      0.0 MiB           2       with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
      "    14    162.1 MiB  -5511.0 MiB      117408           for line in f:\n",
      "    15    162.1 MiB  -5512.7 MiB      117407               total_lines += 1\n",
      "    16    162.1 MiB  -5512.9 MiB      117407               try:\n",
      "    17    162.1 MiB  -5441.4 MiB      117407                   tweet = json.loads(line)\n",
      "    18                                         \n",
      "    19                                                         # Verificación explícita de campos requeridos\n",
      "    20    162.1 MiB  -5441.7 MiB      117407                   if \"date\" not in tweet or \"user\" not in tweet or \"username\" not in tweet[\"user\"]:\n",
      "    21                                                             print(f\"Línea {total_lines} incompleta o mal formada\")\n",
      "    22                                                             continue\n",
      "    23                                         \n",
      "    24    162.1 MiB  -5513.5 MiB      117407                   raw_date = tweet[\"date\"]\n",
      "    25    162.1 MiB  -5513.7 MiB      117407                   username = tweet[\"user\"][\"username\"]\n",
      "    26    162.1 MiB  -5514.0 MiB      117407                   date = parser.isoparse(raw_date).date()\n",
      "    27                                         \n",
      "    28    162.1 MiB  -5512.4 MiB      117407                   date_user_count[date][username] += 1\n",
      "    29    162.1 MiB  -5513.3 MiB      117407                   registros_ok += 1\n",
      "    30                                         \n",
      "    31    162.1 MiB  -5513.5 MiB      117407                   if registros_ok % 10000 == 0:\n",
      "    32    161.8 MiB     -0.4 MiB          11                       print(f\"{registros_ok} tweets procesados correctamente\")\n",
      "    33                                         \n",
      "    34                                                     except Exception as e:\n",
      "    35                                                         errores += 1\n",
      "    36                                                         print(f\"Error en línea {total_lines}: {e}\")\n",
      "    37                                                         print(\"Contenido:\", line.strip())\n",
      "    38                                                         if errores >= 5:\n",
      "    39                                                             print(\"Demasiados errores consecutivos, deteniendo ejecución.\")\n",
      "    40                                                             break\n",
      "    41                                         \n",
      "    42    162.1 MiB      0.0 MiB           1       print(\"\\nResumen del procesamiento\")\n",
      "    43    162.1 MiB      0.0 MiB           1       print(f\"Líneas totales leídas: {total_lines}\")\n",
      "    44    162.1 MiB      0.0 MiB           1       print(f\"Tweets válidos: {registros_ok}\")\n",
      "    45    162.1 MiB      0.0 MiB           1       print(f\"Errores: {errores}\")\n",
      "    46    162.1 MiB      0.0 MiB           1       print(f\"Fechas únicas encontradas: {len(date_user_count)}\")\n",
      "    47                                         \n",
      "    48    162.1 MiB      0.0 MiB          16       total_by_date = {d: sum(users.values()) for d, users in date_user_count.items()}\n",
      "    49    162.1 MiB      0.0 MiB           1       top10_dates = sorted(total_by_date, key=total_by_date.get, reverse=True)[:10]\n",
      "    50    162.1 MiB      0.0 MiB           1       print(\"Top 10 fechas con más tweets:\", top10_dates)\n",
      "    51                                         \n",
      "    52    162.1 MiB      0.0 MiB           1       result = []\n",
      "    53    162.1 MiB     -0.5 MiB          11       for d in top10_dates:\n",
      "    54    162.1 MiB     -0.4 MiB          10           user_counts = date_user_count[d]\n",
      "    55    162.1 MiB     -0.4 MiB          10           if user_counts:\n",
      "    56    162.1 MiB  -3953.5 MiB       88328               top_user = max(user_counts.items(), key=lambda x: x[1])[0]\n",
      "    57    162.1 MiB     -0.5 MiB          10               result.append((d, top_user))\n",
      "    58                                         \n",
      "    59    162.0 MiB     -0.1 MiB           1       return result"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "\n",
    "from q1_memory import q1_memory\n",
    "\n",
    "def wrapper():\n",
    "    return q1_memory(file_path)\n",
    "\n",
    "%mprun -f q1_memory wrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 Emojis\n",
    "En ambas funciones se utiliza casi la misma lógica para encontrar los emojis más usados, solo cambia el cómo se realiza.\n",
    "## q2_time\n",
    "Para este caso la diferencia recae en esta función all_emojis.extend(emojis), donde se están acumulando todos los emojis en una lista para luego usar Counter(all_emojis) en donde se cuentan y se obtiene el total de emojis.\n",
    "\n",
    "## q2_memory\n",
    "En esta función los emojis se cuentan en el mismo momento en el que el proceso lo recorre por medio de counter.update(emojis), por lo que no hay necesidad de almacenar registros en alguna lista.\n",
    "\n",
    "También se generan \"print()\" para ir revisando el código, además de que se generó una carpeta para almacenar un método en común que utilizaban ambos códigos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando emojis\n",
      "Total líneas leídas: 117407\n",
      "Emojis únicos encontrados: 641\n",
      "Top 10 emojis: [('🙏', 7286), ('😂', 3072), ('🚜', 2972), ('✊', 2411), ('🌾', 2363), ('🏻', 2080), ('❤', 1779), ('🤣', 1668), ('🏽', 1218), ('👇', 1108)]\n",
      "[('🙏', 7286), ('😂', 3072), ('🚜', 2972), ('✊', 2411), ('🌾', 2363), ('🏻', 2080), ('❤', 1779), ('🤣', 1668), ('🏽', 1218), ('👇', 1108)]\n",
      "*********************************************\n",
      "Procesando emojis\n",
      "Total líneas leídas: 117407\n",
      "Emojis únicos encontrados: 641\n",
      "Top 10 emojis: [('🙏', 7286), ('😂', 3072), ('🚜', 2972), ('✊', 2411), ('🌾', 2363), ('🏻', 2080), ('❤', 1779), ('🤣', 1668), ('🏽', 1218), ('👇', 1108)]\n",
      "[('🙏', 7286), ('😂', 3072), ('🚜', 2972), ('✊', 2411), ('🌾', 2363), ('🏻', 2080), ('❤', 1779), ('🤣', 1668), ('🏽', 1218), ('👇', 1108)]\n"
     ]
    }
   ],
   "source": [
    "from q2_time import q2_time\n",
    "from q2_memory import q2_memory\n",
    "\n",
    "print(q2_time(file_path))\n",
    "print(\"*********************************************\")\n",
    "print(q2_memory(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3 Menciones de Usuarios\n",
    "## q3_time\n",
    "Se utiliza una lógica muy similar a la anterior en el q2, la diferencia es que se recorren las menciones y los usuarios para luego usar la función all_mentions.append(username), en donde se almacenan las menciones para que al final se realice el conteo con counter = Counter(all_mentions).\n",
    "## q3_memory\n",
    "Para esta situación se realiza el mismo ejercicio de recorrer menciones y usuarios con la diferencia de que se realiza un conteo(contador), en el momento que se recorren las menciones.\n",
    "\n",
    "Se generan print() para revisar el funcionamiento del código.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando menciones de usuarios Version Tiempo\n",
      "Total líneas leídas: 117407\n",
      "Usuarios únicos mencionados: 15239\n",
      "Top 10 usuarios mencionados: [('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n",
      "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n",
      "*********************************************\n",
      " Procesando menciones de usuarios Version Memoria\n",
      "Total líneas leídas: 117407\n",
      "Usuarios únicos mencionados: 15239\n",
      "Top 10 usuarios mencionados: [('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n",
      "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n"
     ]
    }
   ],
   "source": [
    "from q3_time import q3_time\n",
    "from q3_memory import q3_memory\n",
    "\n",
    "print(q3_time(file_path))\n",
    "print(\"*********************************************\")\n",
    "print(q3_memory(file_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
